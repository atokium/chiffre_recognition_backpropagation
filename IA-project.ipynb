{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from extract import extract\n",
    "from crop import crop\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59999\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "# Read in the train and test data and lables :\n",
    "train_data = pd.read_csv('./data_csv/train-extracted.csv')\n",
    "train_lables = pd.read_csv('./data_csv/train-lables.csv')\n",
    "test_data = pd.read_csv('./data_csv/test-extracted.csv')\n",
    "test_lables = pd.read_csv('./data_csv/test-lables.csv')\n",
    "\n",
    "# sheck :\n",
    "print(train_data.shape[0]+1)\n",
    "print(test_data.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop not needed cols :\n",
    "train_data = train_data.drop(\"Unnamed: 0\",axis=1)\n",
    "test_data = test_data.drop(\"Unnamed: 0\",axis=1)\n",
    "train_lables = train_lables.drop(\"Unnamed: 0\",axis=1)\n",
    "test_lables = test_lables.drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# putting lables and data in place :\n",
    "train_y = train_lables.values[:,0]\n",
    "train_x = train_data.values.astype(np.float32)\n",
    "test_y = test_lables.values[:,0]\n",
    "test_x = test_data.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "# shape of lables :\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate how much of our training data is for train and validation.\n",
    "VALIDATION_PERCENT = 0.1\n",
    "num_train = len(train_y)\n",
    "num_val = int(num_train*VALIDATION_PERCENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for train/val.\n",
    "val_x = train_x[0:num_val]\n",
    "val_y = train_y[0:num_val]\n",
    "train_x = train_x[num_val:]\n",
    "train_y = train_y[num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the dataset\n",
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y=None):\n",
    "        self.data = x\n",
    "        self.labels = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.data[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders :\n",
    "train_dataset = MnistDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=30, shuffle=True)\n",
    "\n",
    "test_dataset = MnistDataset(test_x,test_y)\n",
    "test_loader = DataLoader(train_dataset,batch_size=30,shuffle=True)\n",
    "\n",
    "validation_dataset = MnistDataset(val_x, val_y)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=30, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the modele\n",
    "input_size = 32\n",
    "hidden_sizes = [100,70,25]\n",
    "output_size = 10\n",
    "model = nn.Sequential(nn.Conv2d(input_size, hidden_sizes[0],kernel_size=3),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),nn.LogSoftmax(dim=1)\n",
    "                     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36680"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the class :\n",
    "class myNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(32, 100) \n",
    "        self.fc2 = nn.Linear(100, 70)\n",
    "        self.fc3 = nn.Linear(70, 25)\n",
    "        self.fc4 = nn.Linear(25,10)\n",
    "    def forward(self, x):\n",
    "            x = x.view(-1,32)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model object:\n",
    "myModel=myNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12405"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la fonction du coût\n",
    "loss=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction d'optimisation des coût: Adam par exemple.\n",
    "opt = optim.Adam(myModel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le nombre d'epochs. \n",
    "n_epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0\n",
      "coût d'entraînement : tensor(1.1383, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0980)\n",
      "précision : 0.711285214202367\n",
      "------------\n",
      "epoche: 1\n",
      "coût d'entraînement : tensor(0.8656, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0858)\n",
      "précision : 0.744957492915486\n",
      "------------\n",
      "epoche: 2\n",
      "coût d'entraînement : tensor(0.7836, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0818)\n",
      "précision : 0.7562927154525755\n",
      "------------\n",
      "epoche: 3\n",
      "coût d'entraînement : tensor(0.7320, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0770)\n",
      "précision : 0.7701283547257877\n",
      "------------\n",
      "epoche: 4\n",
      "coût d'entraînement : tensor(0.6964, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0738)\n",
      "précision : 0.776129354892482\n",
      "------------\n",
      "epoche: 5\n",
      "coût d'entraînement : tensor(0.6698, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0722)\n",
      "précision : 0.785964327387898\n",
      "------------\n",
      "epoche: 6\n",
      "coût d'entraînement : tensor(0.6477, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0715)\n",
      "précision : 0.7819636606101017\n",
      "------------\n",
      "epoche: 7\n",
      "coût d'entraînement : tensor(0.6315, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0704)\n",
      "précision : 0.7887981330221704\n",
      "------------\n",
      "epoche: 8\n",
      "coût d'entraînement : tensor(0.6185, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0696)\n",
      "précision : 0.7914652442073679\n",
      "------------\n",
      "epoche: 9\n",
      "coût d'entraînement : tensor(0.6063, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0676)\n",
      "précision : 0.7939656609434906\n",
      "------------\n",
      "epoche: 10\n",
      "coût d'entraînement : tensor(0.5951, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0678)\n",
      "précision : 0.7959659943323887\n",
      "------------\n",
      "epoche: 11\n",
      "coût d'entraînement : tensor(0.5844, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0681)\n",
      "précision : 0.7969661610268378\n",
      "------------\n",
      "epoche: 12\n",
      "coût d'entraînement : tensor(0.5754, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0666)\n",
      "précision : 0.7982997166194366\n",
      "------------\n",
      "epoche: 13\n",
      "coût d'entraînement : tensor(0.5696, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0665)\n",
      "précision : 0.8011335222537089\n",
      "------------\n",
      "epoche: 14\n",
      "coût d'entraînement : tensor(0.5632, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0697)\n",
      "précision : 0.7921320220036673\n",
      "------------\n",
      "epoche: 15\n",
      "coût d'entraînement : tensor(0.5547, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0670)\n",
      "précision : 0.8038006334389065\n",
      "------------\n",
      "epoche: 16\n",
      "coût d'entraînement : tensor(0.5487, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0666)\n",
      "précision : 0.8008001333555592\n",
      "------------\n",
      "epoche: 17\n",
      "coût d'entraînement : tensor(0.5421, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0666)\n",
      "précision : 0.8024670778463077\n",
      "------------\n",
      "epoche: 18\n",
      "coût d'entraînement : tensor(0.5369, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0669)\n",
      "précision : 0.8031338556426071\n",
      "------------\n",
      "epoche: 19\n",
      "coût d'entraînement : tensor(0.5325, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0668)\n",
      "précision : 0.8068011335222537\n",
      "------------\n",
      "epoche: 20\n",
      "coût d'entraînement : tensor(0.5276, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0664)\n",
      "précision : 0.8051341890315052\n",
      "------------\n",
      "epoche: 21\n",
      "coût d'entraînement : tensor(0.5231, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0670)\n",
      "précision : 0.803300550091682\n",
      "------------\n",
      "epoche: 22\n",
      "coût d'entraînement : tensor(0.5198, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0672)\n",
      "précision : 0.8046341056842807\n",
      "------------\n",
      "epoche: 23\n",
      "coût d'entraînement : tensor(0.5132, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0691)\n",
      "précision : 0.7994665777629605\n",
      "------------\n",
      "epoche: 24\n",
      "coût d'entraînement : tensor(0.5109, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0674)\n",
      "précision : 0.8019669944990832\n",
      "------------\n",
      "epoche: 25\n",
      "coût d'entraînement : tensor(0.5062, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0674)\n",
      "précision : 0.8051341890315052\n",
      "------------\n",
      "epoche: 26\n",
      "coût d'entraînement : tensor(0.5021, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0669)\n",
      "précision : 0.8073012168694782\n",
      "------------\n",
      "epoche: 27\n",
      "coût d'entraînement : tensor(0.5003, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0693)\n",
      "précision : 0.7951325220870145\n",
      "------------\n",
      "epoche: 28\n",
      "coût d'entraînement : tensor(0.4962, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0672)\n",
      "précision : 0.8044674112352058\n",
      "------------\n",
      "epoche: 29\n",
      "coût d'entraînement : tensor(0.4939, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0673)\n",
      "précision : 0.8063010501750292\n",
      "------------\n",
      "epoche: 30\n",
      "coût d'entraînement : tensor(0.4922, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0680)\n",
      "précision : 0.8009668278046341\n",
      "------------\n",
      "epoche: 31\n",
      "coût d'entraînement : tensor(0.4901, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0685)\n",
      "précision : 0.8056342723787298\n",
      "------------\n",
      "epoche: 32\n",
      "coût d'entraînement : tensor(0.4870, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0676)\n",
      "précision : 0.8066344390731789\n",
      "------------\n",
      "epoche: 33\n",
      "coût d'entraînement : tensor(0.4841, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0688)\n",
      "précision : 0.7981330221703618\n",
      "------------\n",
      "epoche: 34\n",
      "coût d'entraînement : tensor(0.4811, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0693)\n",
      "précision : 0.8051341890315052\n",
      "------------\n",
      "epoche: 35\n",
      "coût d'entraînement : tensor(0.4801, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0680)\n",
      "précision : 0.8091348558093016\n",
      "------------\n",
      "epoche: 36\n",
      "coût d'entraînement : tensor(0.4777, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0686)\n",
      "précision : 0.804300716786131\n",
      "------------\n",
      "epoche: 37\n",
      "coût d'entraînement : tensor(0.4762, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0696)\n",
      "précision : 0.8063010501750292\n",
      "------------\n",
      "epoche: 38\n",
      "coût d'entraînement : tensor(0.4739, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0688)\n",
      "précision : 0.8049674945824304\n",
      "------------\n",
      "epoche: 39\n",
      "coût d'entraînement : tensor(0.4725, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0701)\n",
      "précision : 0.8021336889481581\n",
      "------------\n",
      "epoche: 40\n",
      "coût d'entraînement : tensor(0.4696, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0688)\n",
      "précision : 0.8044674112352058\n",
      "------------\n",
      "epoche: 41\n",
      "coût d'entraînement : tensor(0.4689, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0691)\n",
      "précision : 0.8059676612768795\n",
      "------------\n",
      "epoche: 42\n",
      "coût d'entraînement : tensor(0.4663, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0688)\n",
      "précision : 0.8049674945824304\n",
      "------------\n",
      "epoche: 43\n",
      "coût d'entraînement : tensor(0.4653, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0708)\n",
      "précision : 0.8019669944990832\n",
      "------------\n",
      "epoche: 44\n",
      "coût d'entraînement : tensor(0.4616, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0701)\n",
      "précision : 0.8063010501750292\n",
      "------------\n",
      "epoche: 45\n",
      "coût d'entraînement : tensor(0.4614, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0710)\n",
      "précision : 0.8023003833972329\n",
      "------------\n",
      "epoche: 46\n",
      "coût d'entraînement : tensor(0.4594, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0707)\n",
      "précision : 0.804300716786131\n",
      "------------\n",
      "epoche: 47\n",
      "coût d'entraînement : tensor(0.4590, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0693)\n",
      "précision : 0.8009668278046341\n",
      "------------\n",
      "epoche: 48\n",
      "coût d'entraînement : tensor(0.4576, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0705)\n",
      "précision : 0.8028004667444574\n",
      "------------\n",
      "epoche: 49\n",
      "coût d'entraînement : tensor(0.4546, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0725)\n",
      "précision : 0.7992998833138857\n",
      "------------\n",
      "epoche: 50\n",
      "coût d'entraînement : tensor(0.4547, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0709)\n",
      "précision : 0.8051341890315052\n",
      "------------\n",
      "epoche: 51\n",
      "coût d'entraînement : tensor(0.4521, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0718)\n",
      "précision : 0.7991331888648108\n",
      "------------\n",
      "epoche: 52\n",
      "coût d'entraînement : tensor(0.4497, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0714)\n",
      "précision : 0.8058009668278047\n",
      "------------\n",
      "epoche: 53\n",
      "coût d'entraînement : tensor(0.4491, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0737)\n",
      "précision : 0.7971328554759126\n",
      "------------\n",
      "epoche: 54\n",
      "coût d'entraînement : tensor(0.4503, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0749)\n",
      "précision : 0.7986331055175863\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 55\n",
      "coût d'entraînement : tensor(0.4481, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0727)\n",
      "précision : 0.7997999666611102\n",
      "------------\n",
      "epoche: 56\n",
      "coût d'entraînement : tensor(0.4443, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0733)\n",
      "précision : 0.8004667444574096\n",
      "------------\n",
      "epoche: 57\n",
      "coût d'entraînement : tensor(0.4447, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0734)\n",
      "précision : 0.8018003000500084\n",
      "------------\n",
      "epoche: 58\n",
      "coût d'entraînement : tensor(0.4453, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0723)\n",
      "précision : 0.7996332722120353\n",
      "------------\n",
      "epoche: 59\n",
      "coût d'entraînement : tensor(0.4423, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0725)\n",
      "précision : 0.8029671611935323\n",
      "------------\n",
      "epoche: 60\n",
      "coût d'entraînement : tensor(0.4415, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0722)\n",
      "précision : 0.8036339389898316\n",
      "------------\n",
      "epoche: 61\n",
      "coût d'entraînement : tensor(0.4409, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0730)\n",
      "précision : 0.799966661110185\n",
      "------------\n",
      "epoche: 62\n",
      "coût d'entraînement : tensor(0.4384, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0747)\n",
      "précision : 0.7984664110685115\n",
      "------------\n",
      "epoche: 63\n",
      "coût d'entraînement : tensor(0.4383, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0737)\n",
      "précision : 0.8056342723787298\n",
      "------------\n",
      "epoche: 64\n",
      "coût d'entraînement : tensor(0.4363, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0743)\n",
      "précision : 0.7966327721286881\n",
      "------------\n",
      "epoche: 65\n",
      "coût d'entraînement : tensor(0.4368, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0742)\n",
      "précision : 0.8013002167027838\n",
      "------------\n",
      "epoche: 66\n",
      "coût d'entraînement : tensor(0.4348, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0732)\n",
      "précision : 0.806467744624104\n",
      "------------\n",
      "epoche: 67\n",
      "coût d'entraînement : tensor(0.4346, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0729)\n",
      "précision : 0.80530088348058\n",
      "------------\n",
      "epoche: 68\n",
      "coût d'entraînement : tensor(0.4322, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0735)\n",
      "précision : 0.8019669944990832\n",
      "------------\n",
      "epoche: 69\n",
      "coût d'entraînement : tensor(0.4323, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0747)\n",
      "précision : 0.8023003833972329\n",
      "------------\n",
      "epoche: 70\n",
      "coût d'entraînement : tensor(0.4312, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0746)\n",
      "précision : 0.8021336889481581\n",
      "------------\n",
      "epoche: 71\n",
      "coût d'entraînement : tensor(0.4308, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0748)\n",
      "précision : 0.7981330221703618\n",
      "------------\n",
      "epoche: 72\n",
      "coût d'entraînement : tensor(0.4291, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0732)\n",
      "précision : 0.8046341056842807\n",
      "------------\n",
      "epoche: 73\n",
      "coût d'entraînement : tensor(0.4287, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0745)\n",
      "précision : 0.805467577929655\n",
      "------------\n",
      "epoche: 74\n",
      "coût d'entraînement : tensor(0.4271, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0760)\n",
      "précision : 0.7961326887814636\n",
      "------------\n",
      "epoche: 75\n",
      "coût d'entraînement : tensor(0.4267, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0743)\n",
      "précision : 0.8039673278879813\n",
      "------------\n",
      "epoche: 76\n",
      "coût d'entraînement : tensor(0.4266, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0746)\n",
      "précision : 0.7984664110685115\n",
      "------------\n",
      "epoche: 77\n",
      "coût d'entraînement : tensor(0.4266, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0754)\n",
      "précision : 0.7991331888648108\n",
      "------------\n",
      "epoche: 78\n",
      "coût d'entraînement : tensor(0.4238, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0774)\n",
      "précision : 0.7974662443740623\n",
      "------------\n",
      "epoche: 79\n",
      "coût d'entraînement : tensor(0.4251, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0754)\n",
      "précision : 0.7996332722120353\n",
      "------------\n",
      "epoche: 80\n",
      "coût d'entraînement : tensor(0.4230, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0742)\n",
      "précision : 0.8018003000500084\n",
      "------------\n",
      "epoche: 81\n",
      "coût d'entraînement : tensor(0.4222, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0762)\n",
      "précision : 0.799966661110185\n",
      "------------\n",
      "epoche: 82\n",
      "coût d'entraînement : tensor(0.4212, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0769)\n",
      "précision : 0.8001333555592599\n",
      "------------\n",
      "epoche: 83\n",
      "coût d'entraînement : tensor(0.4213, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0768)\n",
      "précision : 0.8004667444574096\n",
      "------------\n",
      "epoche: 84\n",
      "coût d'entraînement : tensor(0.4201, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0760)\n",
      "précision : 0.7986331055175863\n",
      "------------\n",
      "epoche: 85\n",
      "coût d'entraînement : tensor(0.4189, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0769)\n",
      "précision : 0.8018003000500084\n",
      "------------\n",
      "epoche: 86\n",
      "coût d'entraînement : tensor(0.4177, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0769)\n",
      "précision : 0.7992998833138857\n",
      "------------\n",
      "epoche: 87\n",
      "coût d'entraînement : tensor(0.4177, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0765)\n",
      "précision : 0.8014669111518586\n",
      "------------\n",
      "epoche: 88\n",
      "coût d'entraînement : tensor(0.4167, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0767)\n",
      "précision : 0.8003000500083347\n",
      "------------\n",
      "epoche: 89\n",
      "coût d'entraînement : tensor(0.4162, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0771)\n",
      "précision : 0.7986331055175863\n",
      "------------\n",
      "epoche: 90\n",
      "coût d'entraînement : tensor(0.4140, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0796)\n",
      "précision : 0.796799466577763\n",
      "------------\n",
      "epoche: 91\n",
      "coût d'entraînement : tensor(0.4140, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0774)\n",
      "précision : 0.8004667444574096\n",
      "------------\n",
      "epoche: 92\n",
      "coût d'entraînement : tensor(0.4147, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0776)\n",
      "précision : 0.7964660776796133\n",
      "------------\n",
      "epoche: 93\n",
      "coût d'entraînement : tensor(0.4124, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0774)\n",
      "précision : 0.7981330221703618\n",
      "------------\n",
      "epoche: 94\n",
      "coût d'entraînement : tensor(0.4117, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0767)\n",
      "précision : 0.8004667444574096\n",
      "------------\n",
      "epoche: 95\n",
      "coût d'entraînement : tensor(0.4119, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0792)\n",
      "précision : 0.7959659943323887\n",
      "------------\n",
      "epoche: 96\n",
      "coût d'entraînement : tensor(0.4121, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0793)\n",
      "précision : 0.7996332722120353\n",
      "------------\n",
      "epoche: 97\n",
      "coût d'entraînement : tensor(0.4099, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0790)\n",
      "précision : 0.7981330221703618\n",
      "------------\n",
      "epoche: 98\n",
      "coût d'entraînement : tensor(0.4096, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0782)\n",
      "précision : 0.8004667444574096\n",
      "------------\n",
      "epoche: 99\n",
      "coût d'entraînement : tensor(0.4093, grad_fn=<DivBackward0>)\n",
      "coût de validation : tensor(0.0790)\n",
      "précision : 0.8001333555592599\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    myModel.train()\n",
    "    t_cost= 0.0\n",
    "    for i,(inputs,labels) in enumerate(train_loader):\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        outputs = myModel(inputs)\n",
    "        cout = loss(outputs,labels.long())\n",
    "        # Backpropagation: \n",
    "        # Réinitialiser l'optimiseur\n",
    "        opt.zero_grad()\n",
    "        # Faire la backpropagation\n",
    "        cout.backward()\n",
    "        # Effectuer un pas d'optimisation\n",
    "        opt.step()\n",
    "        # Mettre à jour votre coût d'apprentissage en lui ajoutant le coût du data batch\n",
    "        t_cost += cout\n",
    "    # A la sortie de la boucle de l'entraînement, on calcule le coût moyen pour toutes les données training\n",
    "    t_cout_moy = t_cost/(len(train_loader))\n",
    "    v_cost= 0.0\n",
    "    n_prev = 0\n",
    "    # mode d'évaluation\n",
    "    myModel.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        total_losss =0\n",
    "\n",
    "        for i, data in enumerate(validation_loader):    \n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = myModel(inputs)\n",
    "\n",
    "            cout = loss(outputs,labels.long())\n",
    "\n",
    "            v_cost += cout\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() \n",
    " \n",
    "        v_cout_moy = v_cost/(len(train_loader))\n",
    "        accuracy = correct / total\n",
    "    # show stuff :\n",
    "    print(\"epoche:\",epoch)\n",
    "    print(\"coût d'entraînement :\",t_cout_moy)\n",
    "    print(\"coût de validation :\",v_cout_moy)\n",
    "    print(\"précision :\",accuracy)\n",
    "    print('------------')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9175415385144075\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_test = 0.0\n",
    "n_prev_c = 0\n",
    "\n",
    "with torch.no_grad():        \n",
    "    for i,(inputs,labels) in enumerate(test_loader):        \n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float()\n",
    "            labels = labels.float()\n",
    "            outputs = myModel(inputs)\n",
    "            cout = loss(outputs,labels.long())\n",
    "            c_test+=cout\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item() \n",
    "    c_test_moy = c_test/len(train_loader)\n",
    "        \n",
    "        \n",
    "    # Calculer la précision pour test\n",
    "    n_prev_cmoy = correct/total\n",
    "    print(n_prev_cmoy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -6.6845126 -10.578866    0.5018872  -1.2723503  -2.659951   -4.635231\n",
      "  -18.11028     5.5178003  -1.963344    1.1133583 -46.246838  -46.459198\n",
      "  -44.594738  -45.365467  -45.40426   -44.967503  -45.01489   -47.028625\n",
      "  -46.33198   -46.332596  -45.311314  -46.442867  -46.054955  -46.19259\n",
      "  -45.620045 ]]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# testing the model on a canvas from the gui :\n",
    "\n",
    "my_img = cv2.imread('./image.jpg',0)\n",
    "my_img = crop(my_img)\n",
    "plt.imshow(my_img)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    " \n",
    "val = extract(my_img)\n",
    "hehe = myModel(torch.FloatTensor(val))\n",
    "\n",
    "print(hehe.data.max(1, keepdim=True)[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lable: 0\n",
      "prediction: 0\n",
      "lable: 5\n",
      "prediction: 5\n",
      "lable: 4\n",
      "prediction: 2\n",
      "lable: 9\n",
      "prediction: 9\n",
      "lable: 9\n",
      "prediction: 9\n",
      "lable: 2\n",
      "prediction: 2\n",
      "lable: 1\n",
      "prediction: 1\n",
      "lable: 9\n",
      "prediction: 9\n",
      "lable: 4\n",
      "prediction: 4\n",
      "lable: 8\n",
      "prediction: 8\n",
      "lable: 7\n",
      "prediction: 7\n",
      "lable: 3\n",
      "prediction: 5\n",
      "lable: 9\n",
      "prediction: 9\n",
      "lable: 7\n",
      "prediction: 7\n",
      "lable: 4\n",
      "prediction: 7\n",
      "lable: 4\n",
      "prediction: 9\n",
      "lable: 4\n",
      "prediction: 4\n",
      "lable: 9\n",
      "prediction: 8\n",
      "lable: 2\n",
      "prediction: 5\n",
      "lable: 5\n",
      "prediction: 5\n"
     ]
    }
   ],
   "source": [
    "# showing some test results :\n",
    "for i in range(100,120):\n",
    "    out = myModel(torch.FloatTensor(test_x[i]))\n",
    "    print(\"lable:\",test_y[i])\n",
    "    print(\"prediction:\",out.data.max(1, keepdim=True)[1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally saving the modle to use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(myModel.state_dict(),'./model-80-91')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
